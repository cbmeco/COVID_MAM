{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTW MAM Model V1 \n",
    "# County Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current\n",
      "2020-07-03\n",
      "2020-07-09\n",
      "2020-06-26\n",
      "2020-07-02\n",
      "3 day\n",
      "2020-06-30\n",
      "2020-07-06\n",
      "2020-06-23\n",
      "2020-06-29\n",
      "7 day\n",
      "2020-06-26\n",
      "2020-07-02\n",
      "2020-06-19\n",
      "2020-06-25\n",
      "14 day\n",
      "2020-06-19\n",
      "2020-06-25\n",
      "2020-06-12\n",
      "2020-06-18\n"
     ]
    }
   ],
   "source": [
    "#SET DATE FILTERS & FileName\n",
    "\n",
    "file = 'CountyMAM2_July9_CC.csv'\n",
    "state_file = 'State_MAM2_July9_CC.csv'\n",
    "\n",
    "preval_start = datetime(2020,6,26)\n",
    "preval_start = preval_start.strftime('%Y-%m-%d')\n",
    "preval_end = datetime(2020,7,9)\n",
    "preval_end = preval_end.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start = datetime(2020,7,3)\n",
    "curr_start = curr_start.strftime('%Y-%m-%d')\n",
    "curr_end = datetime(2020,7,9)\n",
    "curr_end= curr_end.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start = datetime(2020,6,26)\n",
    "prev_start = prev_start.strftime('%Y-%m-%d')\n",
    "prev_end = datetime(2020,7,2)\n",
    "prev_end = prev_end.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "#Add 3 more for 3 day look back, 7 day, 14 day##\n",
    "##3 DAY HISTORICAL LOOK BACK##\n",
    "\n",
    "preval_start_3 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_start_3 = preval_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_3 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_end_3 = preval_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_3 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_start_3 = curr_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_3 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_end_3 = curr_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_3 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_start_3 = prev_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_3 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_end_3 = prev_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##7 DAY HISTORICAL LOOK BACK##\n",
    "preval_start_7 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_start_7 = preval_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_7 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_end_7 = preval_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_7 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_start_7 = curr_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_7 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_end_7 = curr_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_7 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_start_7 = prev_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_7 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_end_7 = prev_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##14 HISTORICAL DAY LOOK BACK##\n",
    "preval_start_14 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_start_14 = preval_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_14 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_end_14 = preval_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_14 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_start_14 = curr_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_14 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_end_14 = curr_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_14 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_start_14 = prev_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_14 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_end_14 = prev_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"Current\")\n",
    "# print(preval_start)\n",
    "# print(preval_end)\n",
    "print(curr_start)\n",
    "print(curr_end)\n",
    "print(prev_start)\n",
    "print(prev_end)\n",
    "\n",
    "print(\"3 day\")\n",
    "print(curr_start_3)\n",
    "print(curr_end_3)\n",
    "print(prev_start_3)\n",
    "print(prev_end_3)\n",
    "\n",
    "print(\"7 day\")\n",
    "print(curr_start_7)\n",
    "print(curr_end_7)\n",
    "print(prev_start_7)\n",
    "print(prev_end_7)\n",
    "\n",
    "print(\"14 day\")\n",
    "print(curr_start_14)\n",
    "print(curr_end_14)\n",
    "print(prev_start_14)\n",
    "print(prev_end_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_test_start = 20200704\n",
    "curr_test_end = 20200628\n",
    "prev_test_start = 20200627\n",
    "prev_test_end = 20200621\n",
    "\n",
    "##3 day look back##\n",
    "\n",
    "curr_test_start_3 = 20200701\n",
    "curr_test_end_3 = 20200625\n",
    "prev_test_start_3 = 20200624\n",
    "prev_test_end_3 = 20200618\n",
    "\n",
    "##7day look back##\n",
    "curr_test_start_7 =20200627\n",
    "curr_test_end_7 = 20200621\n",
    "prev_test_start_7 = 20200620\n",
    "prev_test_end_7 = 20200614\n",
    "\n",
    "##14 day look back##\n",
    "curr_test_start_14 = 20200614\n",
    "curr_test_end_14 = 20200608\n",
    "prev_test_start_14 = 20200613\n",
    "prev_test_end_14 = 20200607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATES NEEDED - bring in base file, within base file add in state 2 digit codes\n",
    "#Need to add in the NYC FIPS dummy code\n",
    "\n",
    "#Bring in County Data set\n",
    "nytimes = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "counties = pd.read_csv(nytimes,dtype={'fips': str})\n",
    "\n",
    "\n",
    "\n",
    "base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/base_rtw_v2.csv\"\n",
    "pop_df = pd.read_csv(base,\n",
    "                dtype={'fips': str})\n",
    "\n",
    "state_base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/state_base_v1.csv\"\n",
    "state_pop_df = pd.read_csv(state_base)\n",
    "#pop_df = pd.read_csv(\"base_rtw_v1.csv\",\n",
    "#                dtype={'fips': str})\n",
    "\n",
    "#base['fips2'] = np.where(base['county']=='New York City','36061',base['fips'])\n",
    "\n",
    "counties.loc[counties['county'] == 'New York City', 'fips'] = '36061'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Active Case Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date   county    state   fips  cases  deaths\n",
      "9480   2020-03-24  Autauga  Alabama  01001      1       0\n",
      "10835  2020-03-25  Autauga  Alabama  01001      4       0\n",
      "12367  2020-03-26  Autauga  Alabama  01001      6       0\n",
      "14025  2020-03-27  Autauga  Alabama  01001      6       0\n",
      "15803  2020-03-28  Autauga  Alabama  01001      6       0\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "counties.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(counties.head())\n",
    "\n",
    "#Take difference between rows for new case and new death numbers\n",
    "counties['case_diff'] = counties.cases.diff()\n",
    "counties['death_diff'] = counties.deaths.diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for past 14 days\n",
    "#range_14 = counties[counties['date']>=preval_start]\n",
    "\n",
    "range_14 = counties[(counties['date']>=preval_start) & (counties['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = counties[(counties['date']>=preval_start_3) & (counties['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = counties[(counties['date']>=preval_start_7) & (counties['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = counties[(counties['date']>=preval_start_14) & (counties['date']<=preval_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by FIPS, sum up new Cases for prevalence - for 7 day averages will take mean after filtering for 7 days\n",
    "prevalence_grouped = range_14.groupby(['fips'], as_index=False).sum()\n",
    "\n",
    "#3 day#\n",
    "prevalence_grouped_3 = range_14_3.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_3[\"case_diff_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "prevalence_grouped_7 = range_14_7.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_7[\"case_diff_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "prevalence_grouped_14 = range_14_14.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_14[\"case_diff_14\"] = prevalence_grouped_14[\"case_diff\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join in Prevalence to \n",
    "prevalence_w_pop_a = pd.merge(pop_df,\n",
    "                 prevalence_grouped[['fips','case_diff']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_b = pd.merge(prevalence_w_pop_a,\n",
    "                 prevalence_grouped_3[['fips','case_diff_3']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_c = pd.merge(prevalence_w_pop_b,\n",
    "                 prevalence_grouped_7[['fips','case_diff_7']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "prevalence_w_pop = pd.merge(prevalence_w_pop_c,\n",
    "                 prevalence_grouped_14[['fips','case_diff_14']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  \\\n",
      "0                  0    0             0                  0   \n",
      "1                  0    0             0                  2   \n",
      "2                965  356           201                146   \n",
      "3                  0    0             0                  0   \n",
      "4                  0    0             0                  3   \n",
      "\n",
      "            ...             state_pop Homeloc_count_CCC case_diff case_diff_3  \\\n",
      "0           ...              20100000               673    4294.0      4395.0   \n",
      "1           ...              39937489                93   33271.0     30628.0   \n",
      "2           ...              12659682              3577    5355.0      5357.0   \n",
      "3           ...              29472295                 0       5.0         8.0   \n",
      "4           ...               7378494                 9   36030.0     33265.0   \n",
      "\n",
      "  case_diff_7  case_diff_14  active_cases_100k  active_cases_100k_3day  \\\n",
      "0      4554.0        5158.0          22.835567               23.372687   \n",
      "1     29440.0       22592.0         331.413940              305.086897   \n",
      "2      5202.0        4672.0         103.975878              104.014712   \n",
      "3         8.0           5.0          92.609743              148.175588   \n",
      "4     30867.0       20987.0         803.270334              741.626080   \n",
      "\n",
      "   active_cases_100k_7day  active_cases_100k_14day  \n",
      "0               24.218251                27.430334  \n",
      "1              293.253175               225.039936  \n",
      "2              101.005139                90.714342  \n",
      "3              148.175588                92.609743  \n",
      "4              688.163902               467.894379  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "prevalence_w_pop['active_cases_100k'] = ((prevalence_w_pop['case_diff']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_3day'] = ((prevalence_w_pop['case_diff_3']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_7day'] = ((prevalence_w_pop['case_diff_7']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_14day'] = ((prevalence_w_pop['case_diff_14']/prevalence_w_pop['pop'])*100000)\n",
    "print(prevalence_w_pop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 7 Day Rolling Avgs for Cases & Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Diff datasets for current and previous 7 day periods\n",
    "\n",
    "#join prev and current together with pop\n",
    "\n",
    "range_current7 = counties[(counties['date']>=curr_start) & (counties['date']<=curr_end)]\n",
    "range_prev7 = counties[(counties['date']>=prev_start) & (counties['date']<=prev_end)]\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "range_current7_3 = counties[(counties['date']>=curr_start_3) & (counties['date']<=curr_end_3)]\n",
    "range_prev7_3 = counties[(counties['date']>=prev_start_3) & (counties['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "range_current7_7 = counties[(counties['date']>=curr_start_7) & (counties['date']<=curr_end_7)]\n",
    "range_prev7_7 = counties[(counties['date']>=prev_start_7) & (counties['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "range_current7_14 = counties[(counties['date']>=curr_start_14) & (counties['date']<=curr_end_14)]\n",
    "range_prev7_14 = counties[(counties['date']>=prev_start_14) & (counties['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by with mean\n",
    "current_grouped = range_current7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped = range_prev7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped['curr7_case'] = current_grouped['case_diff']\n",
    "current_grouped['curr7_death'] = current_grouped['death_diff']\n",
    "previous_grouped['prev7_case'] = previous_grouped['case_diff']\n",
    "previous_grouped['prev7_death'] = previous_grouped['death_diff']\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "current_grouped_3 = range_current7_3.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_3 = range_prev7_3.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_3['curr7_case_3day'] = current_grouped_3['case_diff']\n",
    "current_grouped_3['curr7_death_3day'] = current_grouped_3['death_diff']\n",
    "previous_grouped_3['prev7_case_3day'] = previous_grouped_3['case_diff']\n",
    "previous_grouped_3['prev7_death_3day'] = previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "current_grouped_7 = range_current7_7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_7 = range_prev7_7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_7['curr7_case_7day'] = current_grouped_7['case_diff']\n",
    "current_grouped_7['curr7_death_7day'] = current_grouped_7['death_diff']\n",
    "previous_grouped_7['prev7_case_7day'] = previous_grouped_7['case_diff']\n",
    "previous_grouped_7['prev7_death_7day'] = previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "current_grouped_14 = range_current7_14.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_14 = range_prev7_14.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_14['curr7_case_14day'] = current_grouped_14['case_diff']\n",
    "current_grouped_14['curr7_death_14day'] = current_grouped_14['death_diff']\n",
    "previous_grouped_14['prev7_case_14day'] = previous_grouped_14['case_diff']\n",
    "previous_grouped_14['prev7_death_14day'] = previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services        ...          \\\n",
      "0                  0    0             0                  0        ...           \n",
      "1                  0    0             0                  2        ...           \n",
      "2                965  356           201                146        ...           \n",
      "3                  0    0             0                  0        ...           \n",
      "4                  0    0             0                  3        ...           \n",
      "5                  0    0             0                  0        ...           \n",
      "6                  0    0             0                  0        ...           \n",
      "7                388    0            82                 50        ...           \n",
      "8                  0    0             0                  0        ...           \n",
      "9                  0    0             0                  0        ...           \n",
      "\n",
      "   state_pop Homeloc_count_CCC   curr7_case curr7_death curr7_case_3day  \\\n",
      "0   20100000               673   308.000000   18.000000      316.000000   \n",
      "1   39937489                93  2438.714286   33.571429     2256.857143   \n",
      "2   12659682              3577   374.857143    9.571429      379.857143   \n",
      "3   29472295                 0     0.000000    0.000000        0.428571   \n",
      "4    7378494                 9  2629.714286   24.142857     2819.571429   \n",
      "5   39937489                23   456.428571    5.428571      452.571429   \n",
      "6   39937489                50   918.000000    3.142857      888.142857   \n",
      "7   21992985               656  2242.285714   10.571429     1967.142857   \n",
      "8   29472295                 0     1.142857    0.000000        1.571429   \n",
      "9   39937489                 0   643.571429    9.714286      666.142857   \n",
      "\n",
      "   curr7_death_3day  curr7_case_7day  curr7_death_7day  curr7_case_14day  \\\n",
      "0        104.428571       305.428571        105.285714        345.142857   \n",
      "1         29.714286      2314.285714         29.714286       1891.428571   \n",
      "2         10.857143       390.142857         15.571429        353.000000   \n",
      "3          0.000000         0.714286          0.000000          0.428571   \n",
      "4         19.285714      2517.428571         21.285714       1892.142857   \n",
      "5          3.714286       463.714286          3.571429        267.000000   \n",
      "6          5.142857       551.142857          6.857143        358.857143   \n",
      "7         10.857143      1657.285714         11.857143        687.142857   \n",
      "8          0.000000         1.857143          0.000000          0.714286   \n",
      "9          6.571429       627.857143          4.285714        382.142857   \n",
      "\n",
      "   curr7_death_14day  \n",
      "0          26.142857  \n",
      "1          31.285714  \n",
      "2          23.857143  \n",
      "3           0.000000  \n",
      "4          13.714286  \n",
      "5           3.000000  \n",
      "6           8.000000  \n",
      "7          10.857143  \n",
      "8           0.000000  \n",
      "9           3.857143  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Current with population\n",
    "current_w_pop_a = pd.merge(pop_df,\n",
    "                 current_grouped[['fips','curr7_case', 'curr7_death']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "current_w_pop_b = pd.merge(current_w_pop_a,\n",
    "                 current_grouped_3[['fips','curr7_case_3day', 'curr7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop_c = pd.merge(current_w_pop_b,\n",
    "                 current_grouped_7[['fips','curr7_case_7day', 'curr7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop = pd.merge(current_w_pop_c,\n",
    "                 current_grouped_14[['fips','curr7_case_14day', 'curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(current_w_pop.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services        ...          \\\n",
      "0                  0    0             0                  0        ...           \n",
      "1                  0    0             0                  2        ...           \n",
      "2                965  356           201                146        ...           \n",
      "3                  0    0             0                  0        ...           \n",
      "4                  0    0             0                  3        ...           \n",
      "5                  0    0             0                  0        ...           \n",
      "6                  0    0             0                  0        ...           \n",
      "7                388    0            82                 50        ...           \n",
      "8                  0    0             0                  0        ...           \n",
      "9                  0    0             0                  0        ...           \n",
      "\n",
      "   state_pop Homeloc_count_CCC   prev7_case prev7_death prev7_case_3day  \\\n",
      "0   20100000               673   305.428571  105.285714      311.857143   \n",
      "1   39937489                93  2314.285714   29.714286     2118.571429   \n",
      "2   12659682              3577   390.142857   15.571429      385.428571   \n",
      "3   29472295                 0     0.714286    0.000000        0.714286   \n",
      "4    7378494                 9  2517.428571   21.285714     1932.571429   \n",
      "5   39937489                23   463.714286    3.571429      390.857143   \n",
      "6   39937489                50   551.142857    6.857143      374.000000   \n",
      "7   21992985               656  1657.285714   11.857143     1283.285714   \n",
      "8   29472295                 0     1.857143    0.000000        1.000000   \n",
      "9   39937489                 0   627.857143    4.285714      435.428571   \n",
      "\n",
      "   prev7_death_3day  prev7_case_7day  prev7_death_7day  prev7_case_14day  \\\n",
      "0         20.714286       345.142857         26.142857        391.714286   \n",
      "1         27.000000      1891.428571         31.285714       1336.000000   \n",
      "2         18.714286       353.000000         23.857143        314.428571   \n",
      "3          0.000000         0.428571          0.000000          0.285714   \n",
      "4         16.000000      1892.142857         13.714286       1106.000000   \n",
      "5          3.285714       267.000000          3.000000        156.285714   \n",
      "6          8.714286       358.857143          8.000000        152.857143   \n",
      "7         13.000000       687.142857         10.857143        472.285714   \n",
      "8          0.000000         0.714286          0.000000          0.571429   \n",
      "9          2.285714       382.142857          3.857143        318.142857   \n",
      "\n",
      "   prev7_death_14day  \n",
      "0          29.285714  \n",
      "1          30.571429  \n",
      "2          31.714286  \n",
      "3           0.000000  \n",
      "4           9.428571  \n",
      "5           2.714286  \n",
      "6           6.857143  \n",
      "7           8.714286  \n",
      "8           0.000000  \n",
      "9           4.000000  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Previous with population\n",
    "\n",
    "previous_w_pop_a = pd.merge(pop_df,\n",
    "                 previous_grouped[['fips','prev7_case', 'prev7_death']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_b = pd.merge(previous_w_pop_a,\n",
    "                 previous_grouped_3[['fips','prev7_case_3day', 'prev7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_c = pd.merge(previous_w_pop_b,\n",
    "                 previous_grouped_7[['fips','prev7_case_7day', 'prev7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop = pd.merge(previous_w_pop_c,\n",
    "                 previous_grouped_14[['fips','prev7_case_14day', 'prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(previous_w_pop.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_w_pop['cur_7rollavg_cases'] = ((current_w_pop['curr7_case']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths'] = ((current_w_pop['curr7_death']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#3 day#\n",
    "current_w_pop['cur_7rollavg_cases_3day'] = ((current_w_pop['curr7_case_3day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_3day'] = ((current_w_pop['curr7_death_3day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "current_w_pop['cur_7rollavg_cases_7day'] = ((current_w_pop['curr7_case_7day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_7day'] = ((current_w_pop['curr7_death_7day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "current_w_pop['cur_7rollavg_cases_14day'] = ((current_w_pop['curr7_case_14day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_14day'] = ((current_w_pop['curr7_death_14day']/current_w_pop['pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_w_pop['prev_7rollavg_cases'] = ((previous_w_pop['prev7_case']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths'] = ((previous_w_pop['prev7_death']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#3day#\n",
    "previous_w_pop['prev_7rollavg_cases_3day'] = ((previous_w_pop['prev7_case_3day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_3day'] = ((previous_w_pop['prev7_death_3day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "previous_w_pop['prev_7rollavg_cases_7day'] = ((previous_w_pop['prev7_case_7day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_7day'] = ((previous_w_pop['prev7_death_7day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "previous_w_pop['prev_7rollavg_cases_14day'] = ((previous_w_pop['prev7_case_14day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_14day'] = ((previous_w_pop['prev7_death_14day']/previous_w_pop['pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with prevalence dataset\n",
    "prev_curr = pd.merge(prevalence_w_pop,\n",
    "                 current_w_pop[['fips','cur_7rollavg_cases', 'cur_7rollavg_deaths','curr7_case','curr7_death',\n",
    "                               'cur_7rollavg_cases_3day', 'cur_7rollavg_deaths_3day','curr7_case_3day','curr7_death_3day',\n",
    "                               'cur_7rollavg_cases_7day', 'cur_7rollavg_deaths_7day','curr7_case_7day','curr7_death_7day',\n",
    "                                'cur_7rollavg_cases_14day', 'cur_7rollavg_deaths_14day','curr7_case_14day','curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_set = pd.merge(prev_curr,\n",
    "                 previous_w_pop[['fips','prev_7rollavg_cases', 'prev_7rollavg_deaths','prev7_case','prev7_death',\n",
    "                                'prev_7rollavg_cases_3day', 'prev_7rollavg_deaths_3day','prev7_case_3day','prev7_death_3day',\n",
    "                               'prev_7rollavg_cases_7day', 'prev_7rollavg_deaths_7day','prev7_case_7day','prev7_death_7day',\n",
    "                                'prev_7rollavg_cases_14day', 'prev_7rollavg_deaths_14day','prev7_case_14day','prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  \\\n",
      "0                  0    0             0                  0   \n",
      "1                  0    0             0                  2   \n",
      "2                965  356           201                146   \n",
      "3                  0    0             0                  0   \n",
      "4                  0    0             0                  3   \n",
      "\n",
      "           ...            prev7_case_14day prev7_death_14day roll7case_diff  \\\n",
      "0          ...                  391.714286         29.285714       0.008419   \n",
      "1          ...                 1336.000000         30.571429       0.053765   \n",
      "2          ...                  314.428571         31.714286      -0.039180   \n",
      "3          ...                    0.285714          0.000000      -1.000000   \n",
      "4          ...                 1106.000000          9.428571       0.044603   \n",
      "\n",
      "  roll7death_diff roll7case_diff_3day  roll7death_diff_3day  \\\n",
      "0       -0.829037            0.013284              4.041379   \n",
      "1        0.129808            0.065273              0.100529   \n",
      "2       -0.385321           -0.014455             -0.419847   \n",
      "3             NaN           -0.400000                   NaN   \n",
      "4        0.134228            0.458974              0.205357   \n",
      "\n",
      "   roll7case_diff_7day  roll7death_diff_7day  roll7case_diff_14day  \\\n",
      "0            -0.115066              3.027322             -0.118891   \n",
      "1             0.223565             -0.050228              0.415740   \n",
      "2             0.105221             -0.347305              0.122672   \n",
      "3             0.666667                   NaN              0.500000   \n",
      "4             0.330464              0.552083              0.710798   \n",
      "\n",
      "   roll7death_diff_14day  \n",
      "0              -0.107317  \n",
      "1               0.023364  \n",
      "2              -0.247748  \n",
      "3                    NaN  \n",
      "4               0.454545  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create indicators for rolling averages\n",
    "county_set['roll7case_diff'] = ((county_set['cur_7rollavg_cases']-county_set['prev_7rollavg_cases'])/county_set['prev_7rollavg_cases'])\n",
    "county_set['roll7death_diff'] = ((county_set['cur_7rollavg_deaths']-county_set['prev_7rollavg_deaths'])/county_set['prev_7rollavg_deaths'])\n",
    "\n",
    "\n",
    "#3 day#\n",
    "county_set['roll7case_diff_3day'] = ((county_set['cur_7rollavg_cases_3day']-county_set['prev_7rollavg_cases_3day'])/county_set['prev_7rollavg_cases_3day'])\n",
    "county_set['roll7death_diff_3day'] = ((county_set['cur_7rollavg_deaths_3day']-county_set['prev_7rollavg_deaths_3day'])/county_set['prev_7rollavg_deaths_3day'])\n",
    "\n",
    "\n",
    "#7day#\n",
    "county_set['roll7case_diff_7day'] = ((county_set['cur_7rollavg_cases_7day']-county_set['prev_7rollavg_cases_7day'])/county_set['prev_7rollavg_cases_7day'])\n",
    "county_set['roll7death_diff_7day'] = ((county_set['cur_7rollavg_deaths_7day']-county_set['prev_7rollavg_deaths_7day'])/county_set['prev_7rollavg_deaths_7day'])\n",
    "\n",
    "\n",
    "#14 day#\n",
    "county_set['roll7case_diff_14day'] = ((county_set['cur_7rollavg_cases_14day']-county_set['prev_7rollavg_cases_14day'])/county_set['prev_7rollavg_cases_14day'])\n",
    "county_set['roll7death_diff_14day'] = ((county_set['cur_7rollavg_deaths_14day']-county_set['prev_7rollavg_deaths_14day'])/county_set['prev_7rollavg_deaths_14day'])\n",
    "\n",
    "print(county_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in NYTimes state data, diff, do same 7 day rolling avg counts\n",
    "# pull in COVID tracking test data. calculate pos % then rolling avgs\n",
    "# Manually pull in Rt, might drop this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in state level NYT Data\n",
    "nytimes_state = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\"\n",
    "state= pd.read_csv(nytimes_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    state  fips  cases  deaths    State\n",
      "586  2020-03-13  Alabama     1      6       0  Alabama\n",
      "637  2020-03-14  Alabama     1     12       0  Alabama\n",
      "689  2020-03-15  Alabama     1     23       0  Alabama\n",
      "742  2020-03-16  Alabama     1     29       0  Alabama\n",
      "795  2020-03-17  Alabama     1     39       0  Alabama\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "state['State'] = state['state']\n",
    "state.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(state.head())\n",
    "\n",
    "#Take difference between rows for new case and new death numbers\n",
    "state['case_diff'] = state.cases.diff()\n",
    "state['death_diff'] = state.deaths.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE State Prevalence measure\n",
    "#Filter for past 14 days\n",
    "\n",
    "state_range_14 = state[(state['date']>=preval_start) & (state['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = state[(state['date']>=preval_start_3) & (state['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = state[(state['date']>=preval_start_7) & (state['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = state[(state['date']>=preval_start_14) & (state['date']<=preval_end_14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create state group for prevalence\n",
    "\n",
    "state_prevalence_grouped = state_range_14.groupby(['State'], as_index=False).sum()\n",
    "\n",
    "state_prevalence_grouped['state_active'] = state_prevalence_grouped['case_diff']\n",
    "\n",
    "\n",
    "#3 day#\n",
    "state_prevalence_grouped_3 = range_14_3.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_3[\"state_active_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "state_prevalence_grouped_7 = range_14_7.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_7[\"state_active_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "state_prevalence_grouped_14 = range_14_14.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_14[\"state_active_14\"] = prevalence_grouped_14[\"case_diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take Current and previous rolling averages\n",
    "\n",
    "state_range_current7 = state[(state['date']>=curr_start) & (state['date']<=curr_end)]\n",
    "state_range_prev7 = state[(state['date']>=prev_start) & (state['date']<=prev_end)]\n",
    "\n",
    "#3 day look back#\n",
    "state_range_current7_3 = state[(state['date']>=curr_start_3) & (state['date']<=curr_end_3)]\n",
    "state_range_prev7_3 = state[(state['date']>=prev_start_3) & (state['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_range_current7_7 = state[(state['date']>=curr_start_7) & (state['date']<=curr_end_7)]\n",
    "state_range_prev7_7 = state[(state['date']>=prev_start_7) & (state['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_range_current7_14 = state[(state['date']>=curr_start_14) & (state['date']<=curr_end_14)]\n",
    "state_range_prev7_14 = state[(state['date']>=prev_start_14) & (state['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Means\n",
    "#Group by with mean\n",
    "state_current_grouped = state_range_current7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped = state_range_prev7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped['state_curr7_case'] = state_current_grouped['case_diff']\n",
    "state_previous_grouped['state_prev7_case'] = state_previous_grouped['case_diff']\n",
    "state_current_grouped['state_curr7_death'] = state_current_grouped['death_diff']\n",
    "state_previous_grouped['state_prev7_death'] = state_previous_grouped['death_diff']\n",
    "\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "state_current_grouped_3 = state_range_current7_3.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_3 = state_range_prev7_3.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_3['state_curr7_case_3day'] = state_current_grouped_3['case_diff']\n",
    "state_current_grouped_3['state_curr7_death_3day'] = state_current_grouped_3['death_diff']\n",
    "state_previous_grouped_3['state_prev7_case_3day'] = state_previous_grouped_3['case_diff']\n",
    "state_previous_grouped_3['state_prev7_death_3day'] = state_previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_current_grouped_7 = state_range_current7_7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_7 = state_range_prev7_7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_7['state_curr7_case_7day'] = state_current_grouped_7['case_diff']\n",
    "state_current_grouped_7['state_curr7_death_7day'] = state_current_grouped_7['death_diff']\n",
    "state_previous_grouped_7['state_prev7_case_7day'] = state_previous_grouped_7['case_diff']\n",
    "state_previous_grouped_7['state_prev7_death_7day'] = state_previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_current_grouped_14 = state_range_current7_14.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_14 = state_range_prev7_14.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_14['state_curr7_case_14day'] = state_current_grouped_14['case_diff']\n",
    "state_current_grouped_14['state_curr7_death_14day'] = state_current_grouped_14['death_diff']\n",
    "state_previous_grouped_14['state_prev7_case_14day'] = state_previous_grouped_14['case_diff']\n",
    "state_previous_grouped_14['state_prev7_death_14day'] = state_previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services       ...         \\\n",
      "0                  0    0             0                  0       ...          \n",
      "1                  0    0             0                  2       ...          \n",
      "2                965  356           201                146       ...          \n",
      "3                  0    0             0                  0       ...          \n",
      "4                  0    0             0                  3       ...          \n",
      "5                  0    0             0                  0       ...          \n",
      "6                  0    0             0                  0       ...          \n",
      "7                388    0            82                 50       ...          \n",
      "8                  0    0             0                  0       ...          \n",
      "9                  0    0             0                  0       ...          \n",
      "\n",
      "   roll7case_diff_3day roll7death_diff_3day roll7case_diff_7day  \\\n",
      "0             0.013284             4.041379           -0.115066   \n",
      "1             0.065273             0.100529            0.223565   \n",
      "2            -0.014455            -0.419847            0.105221   \n",
      "3            -0.400000                  NaN            0.666667   \n",
      "4             0.458974             0.205357            0.330464   \n",
      "5             0.157895             0.130435            0.736758   \n",
      "6             1.374714            -0.409836            0.535828   \n",
      "7             0.532895            -0.164835            1.411850   \n",
      "8             0.571429                  NaN            1.600000   \n",
      "9             0.529856             1.875000            0.642991   \n",
      "\n",
      "  roll7death_diff_7day roll7case_diff_14day  roll7death_diff_14day  \\\n",
      "0             3.027322            -0.118891              -0.107317   \n",
      "1            -0.050228             0.415740               0.023364   \n",
      "2            -0.347305             0.122672              -0.247748   \n",
      "3                  NaN             0.500000                    NaN   \n",
      "4             0.552083             0.710798               0.454545   \n",
      "5             0.190476             0.708410               0.105263   \n",
      "6            -0.142857             1.347664               0.166667   \n",
      "7             0.092105             0.454930               0.245902   \n",
      "8                  NaN             0.250000                    NaN   \n",
      "9             0.111111             0.201167              -0.035714   \n",
      "\n",
      "   state_active  state_active_3  state_active_7  state_active_14  \n",
      "0        9039.0            18.0            21.0             34.0  \n",
      "1      102103.0            94.0            92.0             87.0  \n",
      "2       11253.0            16.0             8.0              3.0  \n",
      "3      103242.0            64.0            45.0             55.0  \n",
      "4       49486.0            79.0            72.0             90.0  \n",
      "5      102103.0            94.0            92.0             87.0  \n",
      "6      102103.0            94.0            92.0             87.0  \n",
      "7      118700.0            47.0            27.0             20.0  \n",
      "8      103242.0            64.0            45.0             55.0  \n",
      "9      102103.0            94.0            92.0             87.0  \n",
      "\n",
      "[10 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge PREVALENCE sets with base file\n",
    "\n",
    "state_active_a= pd.merge(county_set,\n",
    "                 state_prevalence_grouped[['State','state_active']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_b = pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "state_active_c = pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active = pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(state_active.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  \\\n",
      "0                  0    0             0                  0   \n",
      "1                  0    0             0                  2   \n",
      "2                965  356           201                146   \n",
      "3                  0    0             0                  0   \n",
      "4                  0    0             0                  3   \n",
      "5                  0    0             0                  0   \n",
      "6                  0    0             0                  0   \n",
      "7                388    0            82                 50   \n",
      "8                  0    0             0                  0   \n",
      "9                  0    0             0                  0   \n",
      "\n",
      "            ...             state_curr7_case_14day state_curr7_death_14day  \\\n",
      "0           ...                         661.714286               37.428571   \n",
      "1           ...                        4896.857143               64.428571   \n",
      "2           ...                         693.428571               41.000000   \n",
      "3           ...                        4872.285714               26.285714   \n",
      "4           ...                        2795.142857               29.714286   \n",
      "5           ...                        4896.857143               64.428571   \n",
      "6           ...                        4896.857143               64.428571   \n",
      "7           ...                        4013.142857               38.000000   \n",
      "8           ...                        4872.285714               26.285714   \n",
      "9           ...                        4896.857143               64.428571   \n",
      "\n",
      "  state_prev7_case state_prev7_death state_prev7_case_3day  \\\n",
      "0       639.142857        112.142857            632.428571   \n",
      "1      6683.571429         64.714286           5625.000000   \n",
      "2       781.714286         24.714286            752.857143   \n",
      "3      6496.714286         34.428571           5587.142857   \n",
      "4      3456.857143         38.714286           2833.571429   \n",
      "5      6683.571429         64.714286           5625.000000   \n",
      "6      6683.571429         64.714286           5625.000000   \n",
      "7      7869.714286         41.428571           6589.142857   \n",
      "8      6496.714286         34.428571           5587.142857   \n",
      "9      6683.571429         64.714286           5625.000000   \n",
      "\n",
      "   state_prev7_death_3day  state_prev7_case_7day  state_prev7_death_7day  \\\n",
      "0               29.857143             661.714286               37.428571   \n",
      "1               59.714286            4896.857143               64.428571   \n",
      "2               32.285714             693.428571               41.000000   \n",
      "3               31.000000            4872.285714               26.285714   \n",
      "4               34.857143            2795.142857               29.714286   \n",
      "5               59.714286            4896.857143               64.428571   \n",
      "6               59.714286            4896.857143               64.428571   \n",
      "7               39.142857            4013.142857               38.000000   \n",
      "8               31.000000            4872.285714               26.285714   \n",
      "9               59.714286            4896.857143               64.428571   \n",
      "\n",
      "   state_prev7_case_14day  state_prev7_death_14day  \n",
      "0              695.285714                48.000000  \n",
      "1             3346.571429                59.714286  \n",
      "2              621.428571                49.857143  \n",
      "3             2700.714286                27.857143  \n",
      "4             1743.714286                22.428571  \n",
      "5             3346.571429                59.714286  \n",
      "6             3346.571429                59.714286  \n",
      "7             2408.142857                30.428571  \n",
      "8             2700.714286                27.857143  \n",
      "9             3346.571429                59.714286  \n",
      "\n",
      "[10 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge CURR sets with base file\n",
    "\n",
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day','state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day','state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day', 'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "\n",
    "# print(state_current_w_pop.head(10))\n",
    "\n",
    "\n",
    "county_state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_b = pd.merge(county_state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_c = pd.merge(county_state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df = pd.merge(county_state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(county_state_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create state rolling avg indicator\n",
    "#####NEED TO ADD IN STATE POP to create per 100k \n",
    "\n",
    "county_state_df['state_curr7_case100k'] = ((county_state_df['state_curr7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k'] = ((county_state_df['state_curr7_death']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k'] = ((county_state_df['state_prev7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k'] = ((county_state_df['state_prev7_death']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_curr7_case100k_3day'] = ((county_state_df['state_curr7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_3day'] = ((county_state_df['state_curr7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_3day'] = ((county_state_df['state_prev7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_3day'] = ((county_state_df['state_prev7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_7day'] = ((county_state_df['state_curr7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_7day'] = ((county_state_df['state_curr7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_7day'] = ((county_state_df['state_prev7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_7day'] = ((county_state_df['state_prev7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_14day'] = ((county_state_df['state_curr7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_14day'] = ((county_state_df['state_curr7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_14day'] = ((county_state_df['state_prev7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_14day'] = ((county_state_df['state_prev7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_state_df['state_roll7case_diff'] = ((county_state_df['state_curr7_case100k']-county_state_df['state_prev7_case100k'])/county_state_df['state_prev7_case100k'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_3day'] = ((county_state_df['state_curr7_case100k_3day']-county_state_df['state_prev7_case100k_3day'])/county_state_df['state_prev7_case100k_3day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_7day'] = ((county_state_df['state_curr7_case100k_7day']-county_state_df['state_prev7_case100k_7day'])/county_state_df['state_prev7_case100k_7day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_14day'] = ((county_state_df['state_curr7_case100k_14day']-county_state_df['state_prev7_case100k_14day'])/county_state_df['state_prev7_case100k_14day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  \\\n",
      "0                  0    0             0                  0   \n",
      "1                  0    0             0                  2   \n",
      "2                965  356           201                146   \n",
      "3                  0    0             0                  0   \n",
      "4                  0    0             0                  3   \n",
      "\n",
      "                ...                state_roll7case_diff_7day  \\\n",
      "0               ...                                -0.034111   \n",
      "1               ...                                 0.364870   \n",
      "2               ...                                 0.127318   \n",
      "3               ...                                 0.333402   \n",
      "4               ...                                 0.236737   \n",
      "\n",
      "  state_roll7case_diff_14day state_roll7death_diff state_prevalence_per100k  \\\n",
      "0                  -0.048284             -0.789809                44.970149   \n",
      "1                   0.463246              0.240618               255.657034   \n",
      "2                   0.115862             -0.213873                88.888489   \n",
      "3                   0.804073              0.970954               350.301868   \n",
      "4                   0.602982              0.036900               670.678868   \n",
      "\n",
      "  state_roll7death_diff_3day  state_prevalence_per100k_3day  \\\n",
      "0                   2.674641                       0.089552   \n",
      "1                   0.131579                       0.235368   \n",
      "2                  -0.402655                       0.126385   \n",
      "3                   0.364055                       0.217153   \n",
      "4                  -0.040984                       1.070679   \n",
      "\n",
      "   state_roll7death_diff_7day  state_prevalence_per100k_7day  \\\n",
      "0                    1.996183                       0.104478   \n",
      "1                    0.004435                       0.230360   \n",
      "2                   -0.397213                       0.063193   \n",
      "3                    0.309783                       0.152686   \n",
      "4                    0.302885                       0.975809   \n",
      "\n",
      "   state_roll7death_diff_14day  state_prevalence_per100k_14day  \n",
      "0                    -0.220238                        0.169154  \n",
      "1                     0.078947                        0.217840  \n",
      "2                    -0.177650                        0.023697  \n",
      "3                    -0.056410                        0.186616  \n",
      "4                     0.324841                        1.219761  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "county_state_df['state_roll7death_diff'] = ((county_state_df['state_curr7_death100k']-county_state_df['state_prev7_death100k'])/county_state_df['state_prev7_death100k'])\n",
    "county_state_df['state_prevalence_per100k'] = ((county_state_df['state_active']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_3day'] = ((county_state_df['state_curr7_death100k_3day']-county_state_df['state_prev7_death100k_3day'])/county_state_df['state_prev7_death100k_3day'])\n",
    "county_state_df['state_prevalence_per100k_3day'] = ((county_state_df['state_active_3']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_7day'] = ((county_state_df['state_curr7_death100k_7day']-county_state_df['state_prev7_death100k_7day'])/county_state_df['state_prev7_death100k_7day'])\n",
    "county_state_df['state_prevalence_per100k_7day'] = ((county_state_df['state_active_7']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_14day'] = ((county_state_df['state_curr7_death100k_14day']-county_state_df['state_prev7_death100k_14day'])/county_state_df['state_prev7_death100k_14day'])\n",
    "county_state_df['state_prevalence_per100k_14day'] = ((county_state_df['state_active_14']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "print(county_state_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID TRACKING PROJ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#Bring in COVID TRACKING data\n",
    "url_all = \"https://covidtracking.com/api/v1/states/daily.csv\"\n",
    "testing_all = pd.read_csv(url_all)\n",
    "testing = testing_all[['date','state','positiveIncrease','negativeIncrease', 'totalTestResultsIncrease']]\n",
    "testing['state_code'] = testing['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date state  positiveIncrease  negativeIncrease  \\\n",
      "0  20200712    AK                94              2005   \n",
      "1  20200712    AL              1640              7846   \n",
      "2  20200712    AR              1564             11189   \n",
      "3  20200712    AS                 0                 0   \n",
      "4  20200712    AZ              2537              9645   \n",
      "5  20200712    CA              8460            122444   \n",
      "6  20200712    CO               400              5842   \n",
      "7  20200712    CT                 0                 0   \n",
      "8  20200712    DC                46              2787   \n",
      "9  20200712    DE                61              3233   \n",
      "\n",
      "   totalTestResultsIncrease state_code  \n",
      "0                      2099         AK  \n",
      "1                      9486         AL  \n",
      "2                     12753         AR  \n",
      "3                         0         AS  \n",
      "4                     12182         AZ  \n",
      "5                    130904         CA  \n",
      "6                      6242         CO  \n",
      "7                         0         CT  \n",
      "8                      2833         DC  \n",
      "9                      3294         DE  \n"
     ]
    }
   ],
   "source": [
    "print(testing.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "curr_testing = testing[(testing['date']>=curr_test_end) & (testing['date']<=curr_test_start)]\n",
    "curr_testing['curr_pos_%'] = (curr_testing['positiveIncrease']/curr_testing['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing = testing[(testing['date']>=prev_test_end) & (testing['date']<=prev_test_start)]\n",
    "prev_testing['prev_pos_%'] = (prev_testing['positiveIncrease']/prev_testing['totalTestResultsIncrease'])\n",
    "\n",
    "#3day#\n",
    "curr_testing_3 = testing[(testing['date']>=curr_test_end_3) & (testing['date']<=curr_test_start_3)]\n",
    "curr_testing_3['curr_pos_%_3'] = (curr_testing_3['positiveIncrease']/curr_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_3 = testing[(testing['date']>=prev_test_end_3) & (testing['date']<=prev_test_start_3)]\n",
    "prev_testing_3['prev_pos_%_3'] = (prev_testing_3['positiveIncrease']/prev_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "#7day#\n",
    "curr_testing_7 = testing[(testing['date']>=curr_test_end_7) & (testing['date']<=curr_test_start_7)]\n",
    "curr_testing_7['curr_pos_%_7'] = (curr_testing_7['positiveIncrease']/curr_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_7 = testing[(testing['date']>=prev_test_end_7) & (testing['date']<=prev_test_start_7)]\n",
    "prev_testing_7['prev_pos_%_7'] = (prev_testing_7['positiveIncrease']/prev_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "#14day#\n",
    "curr_testing_14 = testing[(testing['date']>=curr_test_end_14) & (testing['date']<=curr_test_start_14)]\n",
    "curr_testing_14['curr_pos_%_14'] = (curr_testing_14['positiveIncrease']/curr_testing_14['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_14 = testing[(testing['date']>=prev_test_end_14) & (testing['date']<=prev_test_start_14)]\n",
    "prev_testing_14['prev_pos_%_14'] = (prev_testing_14['positiveIncrease']/prev_testing_14['totalTestResultsIncrease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Group by with mean\n",
    "curr_test_grouped = curr_testing.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped = prev_testing.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#3day#\n",
    "curr_test_grouped_3 = curr_testing_3.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_3 = prev_testing_3.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#7day#\n",
    "curr_test_grouped_7 = curr_testing_7.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_7 = prev_testing_7.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#14day#\n",
    "curr_test_grouped_14 = curr_testing_14.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_14 = prev_testing_14.groupby(['state_code'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services      ...        \\\n",
      "0                  0    0             0                  0      ...         \n",
      "1                  0    0             0                  2      ...         \n",
      "2                965  356           201                146      ...         \n",
      "3                  0    0             0                  0      ...         \n",
      "4                  0    0             0                  3      ...         \n",
      "\n",
      "   state_roll7death_diff_3day state_prevalence_per100k_3day  \\\n",
      "0                    2.674641                      0.089552   \n",
      "1                    0.131579                      0.235368   \n",
      "2                   -0.402655                      0.126385   \n",
      "3                    0.364055                      0.217153   \n",
      "4                   -0.040984                      1.070679   \n",
      "\n",
      "  state_roll7death_diff_7day state_prevalence_per100k_7day  \\\n",
      "0                   1.996183                      0.104478   \n",
      "1                   0.004435                      0.230360   \n",
      "2                  -0.397213                      0.063193   \n",
      "3                   0.309783                      0.152686   \n",
      "4                   0.302885                      0.975809   \n",
      "\n",
      "  state_roll7death_diff_14day  state_prevalence_per100k_14day  curr_pos_%  \\\n",
      "0                   -0.220238                        0.169154    0.011062   \n",
      "1                    0.078947                        0.217840    0.071221   \n",
      "2                   -0.177650                        0.023697    0.026334   \n",
      "3                   -0.056410                        0.186616    0.140015   \n",
      "4                    0.324841                        1.219761    0.280260   \n",
      "\n",
      "   curr_pos_%_3  curr_pos_%_7  curr_pos_%_14  \n",
      "0      0.010454      0.010983       0.012013  \n",
      "1      0.065104      0.059177       0.045966  \n",
      "2      0.026709      0.027248       0.039487  \n",
      "3      0.153438      0.152735       0.076933  \n",
      "4      0.261990      0.229032       0.164693  \n",
      "\n",
      "[5 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge to County Set\n",
    "\n",
    "curr_merge_a = pd.merge(county_state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(curr_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services      ...        \\\n",
      "0                  0    0             0                  0      ...         \n",
      "1                  0    0             0                  2      ...         \n",
      "2                965  356           201                146      ...         \n",
      "3                  0    0             0                  0      ...         \n",
      "4                  0    0             0                  3      ...         \n",
      "\n",
      "   state_roll7death_diff_14day state_prevalence_per100k_14day curr_pos_%  \\\n",
      "0                    -0.220238                       0.169154   0.011062   \n",
      "1                     0.078947                       0.217840   0.071221   \n",
      "2                    -0.177650                       0.023697   0.026334   \n",
      "3                    -0.056410                       0.186616   0.140015   \n",
      "4                     0.324841                       1.219761   0.280260   \n",
      "\n",
      "  curr_pos_%_3 curr_pos_%_7  curr_pos_%_14  prev_pos_%  prev_pos_%_3  \\\n",
      "0     0.010454     0.010983       0.012013    0.010983      0.010375   \n",
      "1     0.065104     0.059177       0.045966    0.059177      0.055479   \n",
      "2     0.026709     0.027248       0.039487    0.027248      0.026395   \n",
      "3     0.153438     0.152735       0.076933    0.152735      0.129337   \n",
      "4     0.261990     0.229032       0.164693    0.229032      0.231972   \n",
      "\n",
      "   prev_pos_%_7  prev_pos_%_14  \n",
      "0      0.010216       0.012269  \n",
      "1      0.046327       0.047461  \n",
      "2      0.026493       0.041115  \n",
      "3      0.115113       0.097946  \n",
      "4      0.195719       0.167030  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_b = pd.merge(mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_c = pd.merge(mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2 = pd.merge(mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(mam_v2.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_v2['testing_diff'] = (mam_v2['curr_pos_%'] - mam_v2['prev_pos_%'])\n",
    "mam_v2['testing_diff_3'] = (mam_v2['curr_pos_%_3'] - mam_v2['prev_pos_%_3'])\n",
    "mam_v2['testing_diff_7'] = (mam_v2['curr_pos_%_7'] - mam_v2['prev_pos_%_7'])\n",
    "mam_v2['testing_diff_14'] = (mam_v2['curr_pos_%_14'] - mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services       ...         \\\n",
      "0                  0    0             0                  0       ...          \n",
      "1                  0    0             0                  2       ...          \n",
      "2                965  356           201                146       ...          \n",
      "3                  0    0             0                  0       ...          \n",
      "4                  0    0             0                  3       ...          \n",
      "\n",
      "   curr_pos_%_7 curr_pos_%_14 prev_pos_% prev_pos_%_3 prev_pos_%_7  \\\n",
      "0      0.010983      0.012013   0.010983     0.010375     0.010216   \n",
      "1      0.059177      0.045966   0.059177     0.055479     0.046327   \n",
      "2      0.027248      0.039487   0.027248     0.026395     0.026493   \n",
      "3      0.152735      0.076933   0.152735     0.129337     0.115113   \n",
      "4      0.229032      0.164693   0.229032     0.231972     0.195719   \n",
      "\n",
      "   prev_pos_%_14  testing_diff  testing_diff_3  testing_diff_7  \\\n",
      "0       0.012269      0.000079        0.000078        0.000767   \n",
      "1       0.047461      0.012043        0.009626        0.012850   \n",
      "2       0.041115     -0.000914        0.000314        0.000755   \n",
      "3       0.097946     -0.012720        0.024101        0.037622   \n",
      "4       0.167030      0.051228        0.030018        0.033313   \n",
      "\n",
      "   testing_diff_14  \n",
      "0        -0.000256  \n",
      "1        -0.001495  \n",
      "2        -0.001628  \n",
      "3        -0.021014  \n",
      "4        -0.002337  \n",
      "\n",
      "[5 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "###Filter out any counties with 0 cases for past 14 days##\n",
    "\n",
    "\n",
    "county_filtered = mam_v2[(mam_v2['active_cases_100k']>=0)]\n",
    "print(mam_v2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 7/1\n",
    "\n",
    "def active(n):\n",
    "    if 0<=n<=49.48: score = 0\n",
    "    elif 49.49<=n<=114.05: score = 1\n",
    "    elif 114.06<=n<=100000: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "\n",
    "def roll(n):\n",
    "    if -1<=n<=-0.10: score = 0\n",
    "    elif -0.10<=n<=0.10: score = 1\n",
    "    elif 0.101111<=n<=100: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 0.5  \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd_state(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 1 \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_indicator(n):\n",
    "    if -10000<=n<0.10: score = \"Decreasing or Steady\"\n",
    "    elif 0.10<=n<=10000: score = \"Increasing\"  \n",
    "    else: score = \"Decreasing or Steady\"\n",
    "    return(score)\n",
    "\n",
    "#def test(n):\n",
    "#    if -2<=n<=-.01: score = 0\n",
    "#    elif -.011111<=n<=.01: score = 1\n",
    "#    elif 0.01111 <=n<= 100: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def test7(n):\n",
    "    if -2<=n< 0.03: score = 0\n",
    "    elif 0.03 <=n<.1: score =1\n",
    "    elif 0.1 <=n<0.15: score =2\n",
    "    elif 0.15 <=n<= 1000: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def curr7(n):\n",
    "#    if -2<=n<=4.9999: score = 0\n",
    "#    elif 5 <=n<=9.9999: score =1\n",
    "#    elif 10 <=n<=99999: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def curr7_hrvd(n):\n",
    "    if -222<=n< 2: score = 0\n",
    "    elif 2 <=n<10: score =1\n",
    "    elif 10 <=n<25: score =2\n",
    "    elif 25 <=n<=99999: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def testch(n):\n",
    "    if 0<=n<=0.1: score = 'Decreasing'\n",
    "    elif 1 <=n<= 1.9: score = 'Steady'\n",
    "    else: score = 'Increasing'\n",
    "    return(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "county_filtered['County_Active_100k_Score'] = county_filtered['active_cases_100k'].apply(active)\n",
    "county_filtered['State_Active_100k_Score'] = county_filtered['state_prevalence_per100k'].apply(active)\n",
    "county_filtered['County_Roll_Score'] = county_filtered['roll7case_diff'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend'] = county_filtered['roll7case_diff'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score'] = county_filtered['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score'] = county_filtered['testing_diff'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg'] = county_filtered['curr_pos_%'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg'] = county_filtered['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg'] = county_filtered['cur_7rollavg_cases'].apply(curr7_hrvd)\n",
    "\n",
    "#3day#\n",
    "county_filtered_3day = county_filtered\n",
    "county_filtered['County_Active_100k_Score_3'] = county_filtered['active_cases_100k_3day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_3'] = county_filtered['state_prevalence_per100k_3day'].apply(active)\n",
    "county_filtered['County_Roll_Score_3'] = county_filtered['roll7case_diff_3day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_3'] = county_filtered['roll7case_diff_3day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_3'] = county_filtered['state_roll7case_diff_3day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_3'] = county_filtered['testing_diff_3'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_3'] = county_filtered['curr_pos_%_3'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_3'] = county_filtered['state_curr7_case100k_3day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_3'] = county_filtered['cur_7rollavg_cases_3day'].apply(curr7_hrvd)\n",
    "\n",
    "#7day#\n",
    "county_filtered['County_Active_100k_Score_7'] = county_filtered['active_cases_100k_7day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_7'] = county_filtered['state_prevalence_per100k_7day'].apply(active)\n",
    "county_filtered['County_Roll_Score_7'] = county_filtered['roll7case_diff_7day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_7'] = county_filtered['roll7case_diff_7day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_7'] = county_filtered['state_roll7case_diff_7day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_7'] = county_filtered['testing_diff_7'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_7'] = county_filtered['curr_pos_%_7'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_7'] = county_filtered['state_curr7_case100k_7day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_7'] = county_filtered['cur_7rollavg_cases_7day'].apply(curr7_hrvd)\n",
    "\n",
    "#14day#\n",
    "county_filtered['County_Active_100k_Score_14'] = county_filtered['active_cases_100k_14day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_14'] = county_filtered['state_prevalence_per100k_14day'].apply(active)\n",
    "county_filtered['County_Roll_Score_14'] = county_filtered['roll7case_diff_14day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_14'] = county_filtered['roll7case_diff_14day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_14'] = county_filtered['state_roll7case_diff_14day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_14'] = county_filtered['testing_diff_14'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_14'] = county_filtered['curr_pos_%_14'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_14'] = county_filtered['state_curr7_case100k_14day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_14'] = county_filtered['cur_7rollavg_cases_14day'].apply(curr7_hrvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "county_filtered['State_Composite_Score'] =  ( county_filtered['State_Roll_Score']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "county_filtered['County_Composite_Score'] = (county_filtered['County_Roll_Score'] + county_filtered['County_7Day_New_Case_Rolling_Avg'])\n",
    "\n",
    "#3day#\n",
    "county_filtered['State_Composite_Score_3'] =  ( county_filtered['State_Roll_Score_3']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "county_filtered['County_Composite_Score_3'] = (county_filtered['County_Roll_Score_3'] + county_filtered['County_7Day_New_Case_Rolling_Avg_3'])\n",
    "\n",
    "\n",
    "# #7 day#\n",
    "county_filtered['State_Composite_Score_7'] =  ( county_filtered['State_Roll_Score_7']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "county_filtered['County_Composite_Score_7'] = (county_filtered['County_Roll_Score_7'] + county_filtered['County_7Day_New_Case_Rolling_Avg_7'])\n",
    "\n",
    "\n",
    "# #14 day#\n",
    "county_filtered['State_Composite_Score_14'] =  ( county_filtered['State_Roll_Score_14']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "county_filtered['County_Composite_Score_14'] = (county_filtered['County_Roll_Score_14'] + county_filtered['County_7Day_New_Case_Rolling_Avg_14'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ccolam127\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#def county(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 0.1<=n<=1: score = \"Low\"\n",
    "#    elif 1<n<=2: score = \"Moderate\"\n",
    "#    elif 2<n<=3: score = \"Severe\"\n",
    "#    elif 4<=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def county_hrvd(n):\n",
    "    if 0<=n<0.5: score = \"Minimal\"\n",
    "    elif 0.5<=n<1: score = \"Low\"\n",
    "    elif 1<=n<2: score = \"Moderate\"\n",
    "    elif 2<=n<3: score = \"Elevated\"\n",
    "    elif 3<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "def state(n):\n",
    "    if 0<=n<1: score = \"Minimal\"\n",
    "    elif 1<=n<2: score = \"Low\"\n",
    "    elif 2<=n<4: score = \"Moderate\"\n",
    "    elif 4<=n<6: score = \"Elevated\"\n",
    "    elif 6<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def blend(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 1<=n<=2: score = \"Low\"\n",
    "#    elif 3<=n<=4: score = \"Moderate\"\n",
    "#    elif 5<=n<=6: score = \"Severe\"\n",
    "#    elif 7 <=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "county_filtered['County_Level'] = county_filtered['County_Composite_Score'].apply(county_hrvd)\n",
    "county_filtered['State_Level'] = county_filtered['State_Composite_Score'].apply(state)\n",
    "#county_filtered['County_State_Blend'] = ((county_filtered['County_Composite_Score']+county_filtered['State_Composite_Score']))\n",
    "#county_filtered['County_State_Level'] = county_filtered['County_State_Blend'].apply(blend)\n",
    "\n",
    "#3day, 7 day, 14 day#\n",
    "county_filtered['County_Level_3'] = county_filtered['County_Composite_Score_3'].apply(county_hrvd)\n",
    "county_filtered['State_Level_3'] = county_filtered['State_Composite_Score_3'].apply(state)\n",
    "county_filtered['County_Level_7'] = county_filtered['County_Composite_Score_7'].apply(county_hrvd)\n",
    "county_filtered['State_Level_7'] = county_filtered['State_Composite_Score_7'].apply(state)\n",
    "county_filtered['County_Level_14'] = county_filtered['County_Composite_Score_14'].apply(county_hrvd)\n",
    "county_filtered['State_Level_14'] = county_filtered['State_Composite_Score_14'].apply(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State County_Level State_Level  \\\n",
      "0  36061  New York City    New York      Minimal         Low   \n",
      "1  06037    Los Angeles  California     Elevated    Elevated   \n",
      "2  17031           Cook    Illinois     Moderate         Low   \n",
      "3  48195       Hansford       Texas      Minimal    Critical   \n",
      "4  04013       Maricopa     Arizona     Critical    Critical   \n",
      "\n",
      "   County_Composite_Score  cur_7rollavg_cases     County Case Trend  \\\n",
      "0                     0.0            1.637949  Decreasing or Steady   \n",
      "1                     2.0           24.292144  Decreasing or Steady   \n",
      "2                     1.0            7.278450  Decreasing or Steady   \n",
      "3                     0.0            0.000000  Decreasing or Steady   \n",
      "4                     3.0           58.628129  Decreasing or Steady   \n",
      "\n",
      "   Total CCC  CAE  Cable Stores  Business Services  Tech Ops EE Count  \\\n",
      "0        672    0             0                  0                  0   \n",
      "1         93    0             0                  2                  0   \n",
      "2       3577  356           201                146                965   \n",
      "3          0    0             0                  0                  0   \n",
      "4          9    0             0                  3                  0   \n",
      "\n",
      "  County_Level_3 State_Level_3 County_Level_7 State_Level_7 County_Level_14  \\\n",
      "0        Minimal           Low        Minimal           Low         Minimal   \n",
      "1       Elevated      Elevated       Elevated      Elevated        Elevated   \n",
      "2       Moderate           Low       Moderate      Moderate        Moderate   \n",
      "3       Moderate      Critical       Elevated      Critical        Moderate   \n",
      "4       Critical      Critical       Critical      Critical        Critical   \n",
      "\n",
      "  State_Level_14  \n",
      "0            Low  \n",
      "1       Elevated  \n",
      "2       Moderate  \n",
      "3       Elevated  \n",
      "4       Critical  \n"
     ]
    }
   ],
   "source": [
    "##ADD FIELDS FOR LOOK BACKS HERE\n",
    "\n",
    "county_fields = county_filtered[['fips',\n",
    "    'County','State','County_Level', 'State_Level', 'County_Composite_Score',\n",
    "                                 'cur_7rollavg_cases','County Case Trend',                    \n",
    "                                 'Total CCC','CAE','Cable Stores','Business Services', 'Tech Ops EE Count',\n",
    "                                'County_Level_3','State_Level_3', \n",
    "                                'County_Level_7','State_Level_7', \n",
    "                                'County_Level_14','State_Level_14']]\n",
    "\n",
    "print(county_fields.head())\n",
    "county_fields.to_csv(file,index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create State Only File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge state data with state base file \n",
    "\n",
    "state_active_a= pd.merge(state_pop_df,\n",
    "                 state_prevalence_grouped[['State','state_active',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "#3,7,14 day#\n",
    "state_active_b= pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_c= pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active= pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day',\n",
    "                                       'state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day',\n",
    "                                       'state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day',\n",
    "                                       'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_b = pd.merge(state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_c = pd.merge(state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df = pd.merge(state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create State Level metrics\n",
    "\n",
    "state_df['state_curr7_case100k'] = ((state_df['state_curr7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k'] = ((state_df['state_curr7_death']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k'] = ((state_df['state_prev7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k'] = ((state_df['state_prev7_death']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff'] = ((state_df['state_curr7_case100k']-state_df['state_prev7_case100k'])/state_df['state_prev7_case100k'])\n",
    "state_df['state_roll7death_diff'] = ((state_df['state_curr7_death100k']-state_df['state_prev7_death100k'])/state_df['state_prev7_death100k'])\n",
    "state_df['state_prevalence_per100k'] = ((state_df['state_active']/state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3day\n",
    "state_df['state_curr7_case100k_3'] = ((state_df['state_curr7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_3'] = ((state_df['state_curr7_death_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_3'] = ((state_df['state_prev7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_3'] = ((state_df['state_prev7_death_3day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_3'] = ((state_df['state_curr7_case100k_3']-state_df['state_prev7_case100k_3'])/state_df['state_prev7_case100k_3'])\n",
    "state_df['state_roll7death_diff_3'] = ((state_df['state_curr7_death100k_3']-state_df['state_prev7_death100k_3'])/state_df['state_prev7_death100k_3'])\n",
    "state_df['state_prevalence_per100k_3'] = ((state_df['state_active_3']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "#7day\n",
    "state_df['state_curr7_case100k_7'] = ((state_df['state_curr7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_7'] = ((state_df['state_curr7_death_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_7'] = ((state_df['state_prev7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_7'] = ((state_df['state_prev7_death_7day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_7'] = ((state_df['state_curr7_case100k_7']-state_df['state_prev7_case100k_7'])/state_df['state_prev7_case100k_7'])\n",
    "state_df['state_roll7death_diff_7'] = ((state_df['state_curr7_death100k_7']-state_df['state_prev7_death100k_7'])/state_df['state_prev7_death100k_7'])\n",
    "state_df['state_prevalence_per100k_7'] = ((state_df['state_active_7']/state_df['state_pop'])*100000)\n",
    "\n",
    "#14day\n",
    "state_df['state_curr7_case100k_14'] = ((state_df['state_curr7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_14'] = ((state_df['state_curr7_death_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_14'] = ((state_df['state_prev7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_14'] = ((state_df['state_prev7_death_14day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_14'] = ((state_df['state_curr7_case100k_14']-state_df['state_prev7_case100k_14'])/state_df['state_prev7_case100k_14'])\n",
    "state_df['state_roll7death_diff_14'] = ((state_df['state_curr7_death100k_14']-state_df['state_prev7_death100k_14'])/state_df['state_prev7_death100k_14'])\n",
    "state_df['state_prevalence_per100k_14'] = ((state_df['state_active_14']/state_df['state_pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Covid Tracking Data\n",
    "\n",
    "\n",
    "curr_merge_a = pd.merge(state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']], on='state_code', how='left')\n",
    "\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_b = pd.merge(state_mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_c = pd.merge(state_mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2 = pd.merge(state_mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14',]],\n",
    "                 on='state_code', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_mam_v2['testing_diff'] = (state_mam_v2['curr_pos_%'] - state_mam_v2['prev_pos_%'])\n",
    "state_mam_v2['testing_diff_3'] = (state_mam_v2['curr_pos_%_3'] - state_mam_v2['prev_pos_%_3'])\n",
    "state_mam_v2['testing_diff_7'] = (state_mam_v2['curr_pos_%_7'] - state_mam_v2['prev_pos_%_7'])\n",
    "state_mam_v2['testing_diff_14'] = (state_mam_v2['curr_pos_%_14'] - state_mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Level Scores\n",
    "\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score'] = state_mam_v2['state_prevalence_per100k'].apply(active)\n",
    "state_mam_v2['State_Roll_Score'] = state_mam_v2['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg'] = state_mam_v2['curr_pos_%'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg'] = state_mam_v2['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "\n",
    "#3,7,14 day\n",
    "state_mam_v2['State_Active_100k_Score_3'] = state_mam_v2['state_prevalence_per100k_3'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_3'] = state_mam_v2['state_roll7case_diff_3'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_3'] = state_mam_v2['curr_pos_%_3'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_3'] = state_mam_v2['state_curr7_case100k_3'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_7'] = state_mam_v2['state_prevalence_per100k_7'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_7'] = state_mam_v2['state_roll7case_diff_7'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_7'] = state_mam_v2['curr_pos_%_7'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_7'] = state_mam_v2['state_curr7_case100k_7'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_14'] = state_mam_v2['state_prevalence_per100k_14'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_14'] = state_mam_v2['state_roll7case_diff_14'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_14'] = state_mam_v2['curr_pos_%_14'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_14'] = state_mam_v2['state_curr7_case100k_14'].apply(curr7_hrvd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final dataset\n",
    "\n",
    "state_mam_v2['State Composite Score'] =  (  state_mam_v2['State_Roll_Score']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "state_mam_v2['State Classification'] = state_mam_v2['State Composite Score'].apply(state)\n",
    "#state_mam_v2['Test_Change_Classification'] = state_mam_v2['State_Testing_Score'].apply(testch)\n",
    "\n",
    "\n",
    "#3day\n",
    "state_mam_v2['State Composite Score_3'] =  (  state_mam_v2['State_Roll_Score_3']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "state_mam_v2['State Classification_3'] = state_mam_v2['State Composite Score_3'].apply(state)\n",
    "\n",
    "#7day\n",
    "state_mam_v2['State Composite Score_7'] =  (  state_mam_v2['State_Roll_Score_7']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "state_mam_v2['State Classification_7'] = state_mam_v2['State Composite Score_7'].apply(state)\n",
    "\n",
    "#14 day\n",
    "state_mam_v2['State Composite Score_14'] =  (  state_mam_v2['State_Roll_Score_14']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "state_mam_v2['State Classification_14'] = state_mam_v2['State Composite Score_14'].apply(state)\n",
    "\n",
    "\n",
    "final_state_df = state_mam_v2.query('comcast_state ==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State State Classification  State Composite Score  \\\n",
      "0     Alabama             Critical                      6   \n",
      "2     Arizona             Critical                      6   \n",
      "3    Arkansas             Moderate                      3   \n",
      "4  California             Elevated                      4   \n",
      "5    Colorado             Moderate                      3   \n",
      "\n",
      "   state_curr7_case100k  curr_pos_%  state_roll7case_diff  State_Roll_Score  \\\n",
      "0             26.376334    0.149095              0.312527                 1   \n",
      "2             48.960824    0.280260              0.045045                 0   \n",
      "3             18.695066    0.083636             -0.008971                 0   \n",
      "4             19.787352    0.071221              0.182388                 1   \n",
      "5              5.545144    0.048345              0.212073                 1   \n",
      "\n",
      "   State_7Day_Pos_Test_Avg  State_7Day_New_Case_Rolling_Avg  \\\n",
      "0                        2                                3   \n",
      "2                        3                                3   \n",
      "3                        1                                2   \n",
      "4                        1                                2   \n",
      "5                        1                                1   \n",
      "\n",
      "   Comcast Employees   CAE  Cable Stores  Business Services  Tech Ops  \\\n",
      "0                391    65            36                  8       191   \n",
      "2                720   227            17                  5        86   \n",
      "3                112     1            10                  7        62   \n",
      "4               4747    87           471                215      1966   \n",
      "5               8307  1233           241                694       752   \n",
      "\n",
      "   Warehouse State Classification_3 State Classification_7  \\\n",
      "0         10               Elevated               Elevated   \n",
      "2          2               Critical               Critical   \n",
      "3          4               Moderate               Moderate   \n",
      "4         50               Elevated               Elevated   \n",
      "5         27               Moderate               Moderate   \n",
      "\n",
      "  State Classification_14  \n",
      "0                Elevated  \n",
      "2                Critical  \n",
      "3                Critical  \n",
      "4                Elevated  \n",
      "5                Moderate  \n"
     ]
    }
   ],
   "source": [
    "#Export State File to CSV\n",
    "\n",
    "final_state_df2 = final_state_df[['State', 'State Classification', 'State Composite Score','state_curr7_case100k','curr_pos_%',\n",
    "                                  'state_roll7case_diff', 'State_Roll_Score',\n",
    "                                 'State_7Day_Pos_Test_Avg','State_7Day_New_Case_Rolling_Avg',\n",
    "                                 'Comcast Employees','CAE','Cable Stores','Business Services', 'Tech Ops','Warehouse',\n",
    "                                 'State Classification_3',\n",
    "                                 'State Classification_7',\n",
    "                                 'State Classification_14']]\n",
    "\n",
    "                                  \n",
    "print(final_state_df2.head())\n",
    "final_state_df2.to_csv(state_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State state_code  Comcast Employees  state_pop  CAE  Cable Stores  \\\n",
      "0     Alabama         AL                391    4908621   65            36   \n",
      "1      Alaska         AK                  0    3038999    0             0   \n",
      "2     Arizona         AZ                720    7378494  227            17   \n",
      "3    Arkansas         AR                112    3038999    1            10   \n",
      "4  California         CA               4747   39937489   87           471   \n",
      "\n",
      "   Business Services  Tech Ops  Warehouse  comcast_state  NBCU_pop  \n",
      "0                  8       191         10              1         0  \n",
      "1                  0         0          0              0         0  \n",
      "2                  5        86          2              1       335  \n",
      "3                  7        62          4              1        56  \n",
      "4                215      1966         50              1     12431  \n"
     ]
    }
   ],
   "source": [
    "print(state_pop_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
